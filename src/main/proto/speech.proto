syntax = "proto3";

package com.mobvoi.speech.recognition.v1;

option cc_enable_arenas = true;
option java_outer_classname = "SpeechProto";
option java_package = "com.mobvoi.speech.recognition.v1";

// 语音识别服务
service Speech {
  // 同步语音识别接口
  rpc Recognize(RecognizeRequest) returns (RecognizeResponse);
}

// 语音识别请求
message RecognizeRequest {
  // *必须* 音频参数和数据
  Audio audio = 1;
  // *暂无用*
  int32 nbest = 2;
  // *暂无用*
  bool do_endpoinging = 3;
}

// 语音识别结果
message RecognizeResponse {
  // 语音识别结果列表. 列表每个元素代表音频文件中的一句话的识别结果.
  repeated SingleUtteranceResult results = 1;
}


// 单句话识别结果
message SingleUtteranceResult {
  // 此句话在音频中的开始时间(秒).
  float start_time = 1;
  // 此句话在音频中的结束时间(秒).
  float end_time = 2;
  // 此句话的说话人(比如1, 2 ...).
  string speaker = 3;
  // 语音识别结果数组. 跟请求中的nbest有关. 目前只会返回一个结果.
  repeated SpeechRecognitionAlternative alternatives = 4;
}

message SpeechRecognitionAlternative {
  // 语音识别文本结果.
  string transcript = 1;
  // 暂无用.
  float confidence = 2;
}

// 音频参数和数据
message Audio {
  enum Encoding {
    // 未指定. 会返回错误值 [google.rpc.Code.INVALID_ARGUMENT].
    ENCODING_UNSPECIFIED = 0;

    // 16-bit signed little-endian wav 编码.
    WAV16 = 1;
  }

  // *必须* 音频编码格式
  Encoding encoding = 1;

  // *必须* 音频采样率. 目前只支持8000.
  int32 sample_rate = 2;

  // *必须* 音频通道数量. 目前支持单声道和双声道.
  int32 channel = 3;

  // *必须* 音频数据.
  bytes content = 4;
}
