syntax = "proto3";

package com.mobvoi.speech.recognition.v1;

option cc_enable_arenas = true;
option java_outer_classname = "SpeechProto";
option java_package = "com.mobvoi.speech.recognition.v1";

// 语音识别服务
service Speech {
  // 同步语音识别接口
  rpc Recognize(RecognizeRequest) returns (RecognizeResponse);

  // 双向流式语音识别接口
  rpc StreamingRecognize(stream StreamingRecognizeRequest)
      returns (stream StreamingRecognizeResponse);
}

// 同步语音识别请求
message RecognizeRequest {
  // *必须* 识别参数
  RecognitionConfig config = 1;

  // *必须* 识别音频数据
  RecognitionAudio audio = 2;
}

// 流式语音识别请求
message StreamingRecognizeRequest {
  // *必须* 流式请求内容, streaming_config 和 audio_content二者选一
  oneof streaming_request {
    // 流式请求参数. 第一条StreamingRecognizeRequest是streaming_config.
    StreamingRecognitionConfig streaming_config = 1;

    // 流式请求音频数据.
    // StreamingRecognizeRequest从第二条数据开始必须是audio_content.
    // 音频的编码格式必须在streaming_config里指定.
    bytes audio_content = 2;
  }
}

// 流式请求参数
message StreamingRecognitionConfig {
  // *必须* 识别参数
  RecognitionConfig config = 1;

  // 如果设置成true, 当检测到语音流中没有人说话后,
  // 会返回END_OF_SINGLE_UTTERANCE, 并
  // 停止识别. 默认(或者不设置)值为false.
  bool silence_detection = 2;

  // 如果设置成true, 会在识别过程中试试返回已识别的结果.
  // 默认(或者不设置)值为false.
  bool partial_result = 3;
}

// 语音识别结果
message RecognizeResponse {
  // 语音识别结果. 每个元素代表音频文件中的一句话的识别结果.
  repeated SingleUtteranceResult results = 1;
}

// 单句话识别结果
message SingleUtteranceResult {
  // 此句话在音频中的开始时间(秒).
  float start_time = 1;
  // 此句话在音频中的结束时间(秒).
  float end_time = 2;
  // 此句话的说话人(比如1, 2 ...).
  string speaker = 3;
  // 语音识别结果. 跟请求中的max_alternatives有关. 目前只会返回一个结果.
  repeated SpeechRecognitionAlternative alternatives = 4;
}

// 流式识别结果
message StreamingRecognizeResponse {
  // 识别事件
  enum SpeechEventType {
    // 没有任何事件
    SPEECH_EVENT_UNSPECIFIED = 0;

    // 检测到语音流里无人说话. 当检测到该时间后, 服务端会停止语音识别,
    // 不会再处理任何客户端
    // 发送的语音数据. 客户端在收到此事件后不要再往服务端发送音频数据.
    END_OF_SINGLE_UTTERANCE = 1;
  }

  // 识别出现错误. 服务端不再进行识别, 客户端应停止发送数据.
  Error error = 1;

  // 流式识别语音结果. 当speech_event_type为END_OF_SINGLE_UTTERANCE,
  // 返回的是最终识别结果.
  // 当speech_event_type为SPEECH_EVENT_UNSPECIFIED时, 如果partial_result打开, 会
  // 返回中间识别结果.
  repeated StreamingRecognitionResult results = 2;

  // 识别事件.
  SpeechEventType speech_event_type = 3;
}

// 流式识别语音结果
message StreamingRecognitionResult {
  // 语音识别结果. 跟请求中的max_alternatives有关. 目前只会返回一个结果.
  repeated SpeechRecognitionAlternative alternatives = 1;
}

message SpeechRecognitionAlternative {
  // 语音识别文本结果.
  string transcript = 1;
  // 暂无用.
  float confidence = 2;
}

// 识别参数
message RecognitionConfig {
  enum Encoding {
    // 未指定. 会返回错误值 [google.rpc.Code.INVALID_ARGUMENT].
    ENCODING_UNSPECIFIED = 0;

    // 16-bit signed little-endian wav 编码.
    WAV16 = 1;
  }

  // *必须* 音频编码格式
  Encoding encoding = 1;

  // *必须* 音频采样率. 目前只支持8000.
  int32 sample_rate = 2;

  // *必须* 音频通道数量. 目前支持单声道和双声道.
  int32 channel = 3;

  // *暂无用*
  int32 max_alternatives = 4;
}

// 识别音频数据
message RecognitionAudio {
  // *必须* 音频数据.
  bytes content = 1;
}

// 识别错误
message Error {
  // 错误代码
  enum Code {
    // 无错误
    OK = 0;

    // 服务端取消
    CANCELLED = 1;

    // 未知错误
    UNKNOWN = 2;

    // 请求参数不合法
    INVALID_ARGUMENT = 3;

    // 请求条件不合法
    FAILED_PRECONDITION = 9;
  }

  // 错误代码
  Code code = 1;

  // 错误消息
  string message = 2;
}
